{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49841cbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49841cbe",
        "outputId": "5b789a23-e43f-442f-a453-72b208ea2a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "pip install SpeechRecognition nltk pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0kVRwbjcPmC",
        "outputId": "cb740f02-3f17-448e-c1fb-3b2e54d3345d"
      },
      "id": "Q0kVRwbjcPmC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8nJ0nPdyhR5",
        "outputId": "29343d95-a8e5-4849-9bcb-7807a78a626a"
      },
      "id": "Q8nJ0nPdyhR5",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "26543d88",
      "metadata": {
        "id": "26543d88"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.probability import FreqDist\n",
        "from heapq import nlargest\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4e0cd5c5",
      "metadata": {
        "id": "4e0cd5c5"
      },
      "outputs": [],
      "source": [
        "# Function to split audio file into smaller clips\n",
        "def split_audio(audio_file, chunk_size_ms=5000):\n",
        "    sound = AudioSegment.from_wav(audio_file)\n",
        "    chunks = []\n",
        "    for i in range(0, len(sound), chunk_size_ms):\n",
        "        chunks.append(sound[i:i + chunk_size_ms])\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c9bf07d8",
      "metadata": {
        "id": "c9bf07d8"
      },
      "outputs": [],
      "source": [
        "# Function to convert speech to text\n",
        "def speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "    try:\n",
        "        return recognizer.recognize_google(audio_data)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Speech recognition could not understand audio\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f385aea1",
      "metadata": {
        "id": "f385aea1"
      },
      "outputs": [],
      "source": [
        "# Function to summarize text\n",
        "def summarize_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    frequency_distribution = FreqDist(stemmed_words)\n",
        "\n",
        "    most_frequent_words = nlargest(10, frequency_distribution, key=frequency_distribution.get)\n",
        "    summary_sentences = [sentence for sentence in sentences if any(word in sentence for word in most_frequent_words)]\n",
        "\n",
        "    return ' '.join(summary_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "465a9a5c",
      "metadata": {
        "id": "465a9a5c"
      },
      "outputs": [],
      "source": [
        "# Main function\n",
        "def main(audio_file):\n",
        "    chunks = split_audio(audio_file)\n",
        "    output_text = \"\"\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.export(f\"chunk_{i}.wav\", format=\"wav\")\n",
        "        print(f\"Processing chunk {i}\")\n",
        "        text = speech_to_text(f\"chunk_{i}.wav\")\n",
        "        if text:\n",
        "            summary = summarize_text(text)\n",
        "            output_text += summary + \"\\n\"\n",
        "        else:\n",
        "            print(f\"No speech detected in chunk {i}\")\n",
        "    with open(\"output.txt\", \"w\") as file:\n",
        "        file.write(output_text)\n",
        "\n",
        "    # Clean up temporary files\n",
        "    for i in range(len(chunks)):\n",
        "        os.remove(f\"chunk_{i}.wav\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8ab52d2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ab52d2f",
        "outputId": "8786e389-f399-417e-c938-cbabe7feb7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing chunk 0\n",
            "Processing chunk 1\n",
            "Processing chunk 2\n",
            "Processing chunk 3\n",
            "Processing chunk 4\n",
            "Processing chunk 5\n",
            "Processing chunk 6\n",
            "Processing chunk 7\n",
            "Processing chunk 8\n",
            "Processing chunk 9\n",
            "Processing chunk 10\n",
            "Processing chunk 11\n",
            "Processing chunk 12\n",
            "Processing chunk 13\n",
            "Processing chunk 14\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 14\n",
            "Processing chunk 15\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 15\n",
            "Processing chunk 16\n",
            "Processing chunk 17\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 17\n",
            "Processing chunk 18\n",
            "Processing chunk 19\n",
            "Processing chunk 20\n",
            "Processing chunk 21\n",
            "Processing chunk 22\n",
            "Processing chunk 23\n",
            "Processing chunk 24\n",
            "Processing chunk 25\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 25\n",
            "Processing chunk 26\n",
            "Processing chunk 27\n",
            "Processing chunk 28\n",
            "Processing chunk 29\n",
            "Processing chunk 30\n",
            "Processing chunk 31\n",
            "Processing chunk 32\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 32\n",
            "Processing chunk 33\n",
            "Processing chunk 34\n",
            "Processing chunk 35\n",
            "Processing chunk 36\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 36\n",
            "Processing chunk 37\n",
            "Processing chunk 38\n",
            "Processing chunk 39\n",
            "Processing chunk 40\n",
            "Processing chunk 41\n",
            "Processing chunk 42\n",
            "Processing chunk 43\n",
            "Processing chunk 44\n",
            "Processing chunk 45\n",
            "Processing chunk 46\n",
            "Processing chunk 47\n",
            "Processing chunk 48\n",
            "Processing chunk 49\n",
            "Processing chunk 50\n",
            "Processing chunk 51\n",
            "Processing chunk 52\n",
            "Processing chunk 53\n",
            "Processing chunk 54\n",
            "Processing chunk 55\n",
            "Processing chunk 56\n",
            "Processing chunk 57\n",
            "Processing chunk 58\n",
            "Processing chunk 59\n",
            "Processing chunk 60\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 60\n",
            "Processing chunk 61\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 61\n",
            "Processing chunk 62\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 62\n",
            "Processing chunk 63\n",
            "Processing chunk 64\n",
            "Processing chunk 65\n",
            "Processing chunk 66\n",
            "Processing chunk 67\n",
            "Processing chunk 68\n",
            "Processing chunk 69\n",
            "Processing chunk 70\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 70\n",
            "Processing chunk 71\n",
            "Processing chunk 72\n",
            "Processing chunk 73\n",
            "Processing chunk 74\n",
            "Processing chunk 75\n",
            "Processing chunk 76\n",
            "Processing chunk 77\n",
            "Processing chunk 78\n",
            "Processing chunk 79\n",
            "Processing chunk 80\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 80\n",
            "Processing chunk 81\n",
            "Processing chunk 82\n",
            "Processing chunk 83\n",
            "Processing chunk 84\n",
            "Speech recognition could not understand audio\n",
            "No speech detected in chunk 84\n",
            "Processing chunk 85\n",
            "Processing chunk 86\n",
            "Processing chunk 87\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    audio_file = \"long1.wav\"  # Replace with your audio file path\n",
        "    # audio_file = \"D:\\long1.wav\"  # Replace with your audio file\n",
        "    main(audio_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060c101a",
      "metadata": {
        "id": "060c101a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}